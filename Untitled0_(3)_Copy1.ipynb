{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Untitled0 (3)-Copy1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PulkitKhator/Kriti-ML-leaf-recognition-system/blob/main/Untitled0_(3)_Copy1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BvLQ_TkUFuC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "add08470-9517-41cb-a12d-2a0abc7f882a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ujz9JUeHP9hA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "outputId": "240b9d49-dced-4f3f-ed29-5739e38bddec"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "from keras import Sequential\n",
        "import keras\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
        "from keras.optimizers import SGD\n",
        "from keras import regularizers\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "input_shape = (224, 224, 3)\n",
        "\n",
        "#Instantiate an empty model\n",
        "model = Sequential([\n",
        "Conv2D(64, (3, 3), input_shape=input_shape, padding='same', activation='relu'),\n",
        "Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "BatchNormalization(),\n",
        "Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "Conv2D(128, (3, 3), activation='relu', padding='same',),\n",
        "MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "BatchNormalization(),\n",
        "Conv2D(256, (3, 3), activation='relu', padding='same',),\n",
        "Conv2D(256, (3, 3), activation='relu', padding='same',),\n",
        "Conv2D(256, (3, 3), activation='relu', padding='same',),\n",
        "MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "BatchNormalization(),\n",
        "Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
        "Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
        "Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
        "MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "BatchNormalization(),\n",
        "Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
        "Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
        "Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
        "MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "BatchNormalization(),\n",
        "Flatten(),\n",
        "Dense(2048, activation='relu'),\n",
        "Dense(1024, activation='relu'),\n",
        "Dense(185, activation='softmax')\n",
        "])\n",
        "# (4) Compile \n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZB-3jwTsAGK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ee08904f-3873-41c2-a66e-686deb5c6196"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 112, 112, 64)      256       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 56, 56, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 28, 28, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 7, 7, 512)         2048      \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2048)              51382272  \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1024)              2098176   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 185)               189625    \n",
            "=================================================================\n",
            "Total params: 68,390,649\n",
            "Trainable params: 68,387,705\n",
            "Non-trainable params: 2,944\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXfG7EmWQHts",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "26f31429-80b5-4c3a-a071-ba7d289af82b"
      },
      "source": [
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import TensorBoard\n",
        "from time import time\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.utils import plot_model\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "train_datagen=ImageDataGenerator(preprocessing_function=preprocess_input) #included in our dependencies\n",
        "\n",
        "train_generator=train_datagen.flow_from_directory('drive/My Drive/dataset/train/', # this is where you specify the path to the main data folder\n",
        "                                                 target_size=(224,224),\n",
        "                                                 color_mode='rgb',\n",
        "                                                 batch_size=64,\n",
        "                                                 class_mode='categorical',\n",
        "                                                 shuffle=True)\n",
        "valid_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "valid_generator=valid_datagen.flow_from_directory('drive/My Drive/dataset/test/', # this is where you specify the path to the main data folder\n",
        "                                                 target_size=(224,224),\n",
        "                                                 color_mode='rgb',\n",
        "                                                 batch_size=64,\n",
        "                                                 class_mode='categorical',\n",
        "                                                 shuffle=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 24694 images belonging to 185 classes.\n",
            "Found 3090 images belonging to 185 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "SWOcYT4UpZ4z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 826
        },
        "outputId": "11dd65eb-3a26-4fa8-c5b2-2b3fd4faabd6"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "# autosave best Model\n",
        "best_model_file = \"vgg16.h5\"\n",
        "best_model = ModelCheckpoint(best_model_file, monitor='val_acc', verbose=1, save_best_only=True)\n",
        "# Train the model\n",
        "history = model.fit_generator(\n",
        "      train_generator, validation_data=valid_generator,validation_steps=valid_generator.samples/valid_generator.batch_size,\n",
        "      steps_per_epoch=train_generator.samples/train_generator.batch_size ,\n",
        "      epochs=10,callbacks=[best_model],\n",
        "      verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/10\n",
            "386/385 [==============================] - 764s 2s/step - loss: 4.3745 - acc: 0.0839 - val_loss: 6.1403 - val_acc: 0.0129\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.01294, saving model to vgg16.h5\n",
            "Epoch 2/10\n",
            "386/385 [==============================] - 733s 2s/step - loss: 2.9140 - acc: 0.2462 - val_loss: 3.0583 - val_acc: 0.2301\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.01294 to 0.23010, saving model to vgg16.h5\n",
            "Epoch 3/10\n",
            "386/385 [==============================] - 733s 2s/step - loss: 2.1738 - acc: 0.3948 - val_loss: 4.1836 - val_acc: 0.1835\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.23010\n",
            "Epoch 4/10\n",
            "386/385 [==============================] - 732s 2s/step - loss: 1.6985 - acc: 0.5020 - val_loss: 2.5977 - val_acc: 0.3618\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.23010 to 0.36181, saving model to vgg16.h5\n",
            "Epoch 5/10\n",
            "386/385 [==============================] - 733s 2s/step - loss: 1.3527 - acc: 0.5900 - val_loss: 2.2573 - val_acc: 0.4324\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.36181 to 0.43236, saving model to vgg16.h5\n",
            "Epoch 6/10\n",
            "386/385 [==============================] - 733s 2s/step - loss: 1.0954 - acc: 0.6604 - val_loss: 2.6773 - val_acc: 0.4152\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.43236\n",
            "Epoch 7/10\n",
            "386/385 [==============================] - 732s 2s/step - loss: 0.9018 - acc: 0.7159 - val_loss: 1.9584 - val_acc: 0.5181\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.43236 to 0.51812, saving model to vgg16.h5\n",
            "Epoch 8/10\n",
            "386/385 [==============================] - 732s 2s/step - loss: 0.7657 - acc: 0.7555 - val_loss: 2.0899 - val_acc: 0.4951\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.51812\n",
            "Epoch 9/10\n",
            "386/385 [==============================] - 733s 2s/step - loss: 0.6462 - acc: 0.7883 - val_loss: 1.4112 - val_acc: 0.6301\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.51812 to 0.63010, saving model to vgg16.h5\n",
            "Epoch 10/10\n",
            "386/385 [==============================] - 733s 2s/step - loss: 0.5426 - acc: 0.8214 - val_loss: 2.6435 - val_acc: 0.4951\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.63010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57IO7FsxQaHF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "outputId": "cd6c5eb7-f011-418a-df71-526c572086b4"
      },
      "source": [
        "# Train the model\n",
        "history = model.fit_generator(\n",
        "      train_generator, validation_data=valid_generator,validation_steps=valid_generator.samples/valid_generator.batch_size,\n",
        "      steps_per_epoch=train_generator.samples/train_generator.batch_size ,\n",
        "      epochs=10,callbacks=[best_model],\n",
        "      verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "386/385 [==============================] - 732s 2s/step - loss: 0.4794 - acc: 0.8405 - val_loss: 1.4707 - val_acc: 0.6466\n",
            "\n",
            "Epoch 00001: val_acc improved from 0.63010 to 0.64660, saving model to vgg16.h5\n",
            "Epoch 2/10\n",
            "386/385 [==============================] - 731s 2s/step - loss: 0.4435 - acc: 0.8524 - val_loss: 1.3131 - val_acc: 0.6773\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.64660 to 0.67735, saving model to vgg16.h5\n",
            "Epoch 3/10\n",
            "386/385 [==============================] - 731s 2s/step - loss: 0.3547 - acc: 0.8817 - val_loss: 1.6345 - val_acc: 0.6405\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.67735\n",
            "Epoch 4/10\n",
            "386/385 [==============================] - 731s 2s/step - loss: 0.3102 - acc: 0.8956 - val_loss: 1.4284 - val_acc: 0.6848\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.67735 to 0.68479, saving model to vgg16.h5\n",
            "Epoch 5/10\n",
            "386/385 [==============================] - 731s 2s/step - loss: 0.2936 - acc: 0.9042 - val_loss: 1.4738 - val_acc: 0.6828\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.68479\n",
            "Epoch 6/10\n",
            "386/385 [==============================] - 730s 2s/step - loss: 0.2717 - acc: 0.9080 - val_loss: 2.0482 - val_acc: 0.6188\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.68479\n",
            "Epoch 7/10\n",
            "386/385 [==============================] - 730s 2s/step - loss: 0.2304 - acc: 0.9253 - val_loss: 2.5999 - val_acc: 0.5647\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.68479\n",
            "Epoch 8/10\n",
            "386/385 [==============================] - 730s 2s/step - loss: 0.2503 - acc: 0.9168 - val_loss: 1.7412 - val_acc: 0.6657\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.68479\n",
            "Epoch 9/10\n",
            "386/385 [==============================] - 730s 2s/step - loss: 0.1993 - acc: 0.9331 - val_loss: 1.5682 - val_acc: 0.6900\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.68479 to 0.68997, saving model to vgg16.h5\n",
            "Epoch 10/10\n",
            "386/385 [==============================] - 730s 2s/step - loss: 0.1833 - acc: 0.9379 - val_loss: 1.6817 - val_acc: 0.6926\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.68997 to 0.69256, saving model to vgg16.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1D0PQvK0aRKV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "outputId": "71b0c484-5a0f-4756-9a47-f1ab5efa4a7a"
      },
      "source": [
        "# Train the model\n",
        "history = model.fit_generator(\n",
        "      train_generator, validation_data=valid_generator,validation_steps=valid_generator.samples/valid_generator.batch_size,\n",
        "      steps_per_epoch=train_generator.samples/train_generator.batch_size ,\n",
        "      epochs=10,callbacks=[best_model],\n",
        "      verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "386/385 [==============================] - 728s 2s/step - loss: 0.1702 - acc: 0.9431 - val_loss: 1.7406 - val_acc: 0.6777\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.69256\n",
            "Epoch 2/10\n",
            "386/385 [==============================] - 730s 2s/step - loss: 0.1678 - acc: 0.9460 - val_loss: 1.8081 - val_acc: 0.6828\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.69256\n",
            "Epoch 3/10\n",
            "386/385 [==============================] - 729s 2s/step - loss: 0.1823 - acc: 0.9418 - val_loss: 1.6901 - val_acc: 0.7023\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.69256 to 0.70227, saving model to vgg16.h5\n",
            "Epoch 4/10\n",
            "386/385 [==============================] - 728s 2s/step - loss: 0.1675 - acc: 0.9437 - val_loss: 2.0620 - val_acc: 0.6673\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.70227\n",
            "Epoch 5/10\n",
            "386/385 [==============================] - 728s 2s/step - loss: 0.1560 - acc: 0.9498 - val_loss: 1.7428 - val_acc: 0.6945\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.70227\n",
            "Epoch 6/10\n",
            "386/385 [==============================] - 729s 2s/step - loss: 0.1370 - acc: 0.9543 - val_loss: 1.7019 - val_acc: 0.7133\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.70227 to 0.71327, saving model to vgg16.h5\n",
            "Epoch 7/10\n",
            "386/385 [==============================] - 729s 2s/step - loss: 0.1405 - acc: 0.9556 - val_loss: 1.8040 - val_acc: 0.6977\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.71327\n",
            "Epoch 8/10\n",
            "386/385 [==============================] - 729s 2s/step - loss: 0.0968 - acc: 0.9669 - val_loss: 1.8412 - val_acc: 0.7100\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.71327\n",
            "Epoch 9/10\n",
            "386/385 [==============================] - 729s 2s/step - loss: 0.1372 - acc: 0.9574 - val_loss: 1.7493 - val_acc: 0.7220\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.71327 to 0.72201, saving model to vgg16.h5\n",
            "Epoch 10/10\n",
            "386/385 [==============================] - 726s 2s/step - loss: 0.1457 - acc: 0.9549 - val_loss: 1.7872 - val_acc: 0.7081\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.72201\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USvpoTPGjKzg"
      },
      "source": [
        "pred=model.predict(train_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aC8b2zuPiF6O"
      },
      "source": [
        "l=[]\n",
        "num=0\n",
        "top_3=[]\n",
        "top=[]\n",
        "for labels in train_generator.class_indices:\n",
        "  l.append(labels)\n",
        "for i in pred:\n",
        "  ind1=np.argpartition(i,-1)[-1:]\n",
        "  ind1=np.argpartition(i,-3)[-3:]\n",
        "  for j in range(3):\n",
        "    l1,l2,l3=l[ind3[0]],l[ind3[1]],l[ind3[2]]\n",
        "  top_3.append([num,l1,l2,l3])\n",
        "  top.append([num,l[ind1[0]]])\n",
        "  num+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAaTEfnklR2p"
      },
      "source": [
        "top_3[3000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EW6c2D5hlRIG"
      },
      "source": [
        "top"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9hrxPQ7RDLs"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "acc = history.history['acc']\n",
        "loss = history.history['loss']\n",
        " \n",
        "epochs = range(len(acc))\n",
        " \n",
        "plt.plot(epochs, acc, 'b', label='Training acc')\n",
        "plt.title('Training and accuracy')\n",
        "plt.legend()\n",
        " \n",
        "plt.figure()\n",
        " \n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.title('Training and loss')\n",
        "plt.legend()\n",
        " \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdqaI8eapZ4s"
      },
      "source": [
        "from keras import models\n",
        "model = models.load_model(\"alexnet.h5\")\n",
        "evaltest =  model.evaluate_generator(test_generator,steps=test_generator.samples/test_generator.batch_size)\n",
        "for name, val in zip(model.metrics_names, evaltest):\n",
        "  print(name, val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUxDndcTpZ4u"
      },
      "source": [
        "evaltest =  model.evaluate_generator(train_generator,steps=train_generator.samples/train_generator.batch_size)\n",
        "for name, val in zip(model.metrics_names, evaltest):\n",
        "  print(name, val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTF9gSu6pZ43"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r08DBNYVpZ44"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}